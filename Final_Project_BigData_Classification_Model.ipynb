{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FT3ACDiwkTb1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnArcM5AnIDD"
      },
      "source": [
        "# Install Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iv3qw3HXsX-",
        "outputId": "6fabf6cc-ce3f-4c07-d87d-16db08046abd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=de1b405f66eac2a4a793e084a6e9194ad5777ff79856ca6b28199cfe7e04e958\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqzsaLCnnRrv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "import re\n",
        "import json\n",
        "import itertools\n",
        "import ast\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import pandas as pd\n",
        "from operator import add\n",
        "import numpy as np\n",
        "import nltk \n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from sklearn import metrics "
      ],
      "metadata": {
        "id": "J5N4HsjGXuXS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.feature import VectorAssembler, Imputer , StandardScaler\n",
        "from pyspark.ml.classification import NaiveBayes"
      ],
      "metadata": {
        "id": "NW0A6x8HRgi1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LinearSVC"
      ],
      "metadata": {
        "id": "4gZhcjntZAV6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIyP73soBXco",
        "outputId": "a26ec4cc-97eb-45cf-fdae-603d40a01475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Data"
      ],
      "metadata": {
        "id": "FT3ACDiwkTb1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2I2wPz7GYkw"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOJykM7mOUvJ"
      },
      "outputs": [],
      "source": [
        "#!gdown --id 1Ba72Gnrjre0KPqhWbQPbyYR3XBguosGf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-FhtqwnOWm-"
      },
      "outputs": [],
      "source": [
        "#!unzip 'imdb-review-dataset.zip' -d '/content/drive/MyDrive/BigData_FinalProject/Data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp '/content/imdb-review-dataset.zip' '/content/drive/MyDrive/BigData_FinalProject'"
      ],
      "metadata": {
        "id": "ve9lLLv0mDJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/BigData_FinalProject/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGB-L1eKQhd8",
        "outputId": "e5dbdfb7-e28c-44bd-9df6-52fc07e8949d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! kaggle datasets download ebiswas/imdb-review-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky3-viO7Q5z8",
        "outputId": "371affc4-b620-4cf0-febe-1c4eda05e200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imdb-review-dataset.zip to /content\n",
            "100% 2.69G/2.69G [00:23<00:00, 132MB/s]\n",
            "100% 2.69G/2.69G [00:23<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip imdb-review-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQGIWnkuM5jx",
        "outputId": "2f09cd30-4170-4488-95ae-ada160fde829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb-review-dataset.zip\n",
            "  inflating: part-01.json            \n",
            "  inflating: part-02.json            \n",
            "  inflating: part-03.json            \n",
            "  inflating: part-04.json            \n",
            "  inflating: part-05.json            \n",
            "  inflating: part-06.json            \n",
            "  inflating: sample.json             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip 'imdb-review-dataset.zip' -d '/content/drive/MyDrive/BigData_FinalProject/Data'"
      ],
      "metadata": {
        "id": "w73vCSIXMqOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "f = open('/content/drive/MyDrive/BigData_FinalProject/Data/sample.json')\n",
        "data = json.load(f)\n",
        "'''"
      ],
      "metadata": {
        "id": "1V2ASRoHigRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open(f'new.json', 'a') as f:\n",
        "    json.dump(data[0:50000], f)\n",
        "'''"
      ],
      "metadata": {
        "id": "XzLQnssQWg-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new_data = json.load(open('new.json'))"
      ],
      "metadata": {
        "id": "t_3bCOGoVBpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp '/content/new.json' '/content/drive/MyDrive/BigData_FinalProject'"
      ],
      "metadata": {
        "id": "kwqiybeWn9LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJoosyTSKjP4"
      },
      "source": [
        "### 1. Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbAS12mnHS4"
      },
      "source": [
        "# Create Spark Context and Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-NuJVCOAnYME"
      },
      "outputs": [],
      "source": [
        "# Creating spark context\n",
        "sc = pyspark.SparkContext(appName=\"Final_Project\")\n",
        "# Create a spark session\n",
        "spark = SparkSession(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data by Spark (Dataframes)"
      ],
      "metadata": {
        "id": "q2grhyyDj-hu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3KwVGir-A6Qk"
      },
      "outputs": [],
      "source": [
        "# Reading the data and combine all parts in a single RDD\n",
        "path = '/content/drive/MyDrive/BigData_FinalProject/Splits1/*.json'\n",
        "data_rdd = spark.read.option(\"multiline\",\"true\").json(path).rdd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_rdd.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LBibpKSbYi3",
        "outputId": "988b78ba-844b-4005-81a5-8a1198a3e778"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(helpful=['1', '2'], movie='Private Parts (1997)', rating='9', review_date='3 November 1998', review_detail=\"If you didn't know the man portraying Howard Stern in this movie was himself, you'd think the guy playing the part really nailed it. You never get the sense that Mr. Stern is blowing his own horn:rather, you feel the undercurrent of a genius always on the verge of another breakthrough, and that is the appeal of this film.  Anyone could have made a documentary of Mr. Stern (some have tried, and fell far short of their mark) but no one can deny that Private Parts says it all: it's just a bonus that we see it from the man himself.\", review_id='rw0429696', review_summary='Mr. Stern portrays himself with panache...', reviewer='tilly-3', spoiler_tag=0),\n",
              " Row(helpful=['29', '41'], movie='Private Parts (1997)', rating=None, review_date='20 July 2001', review_detail='This gem of a flick is the great Rockyesque story of shock jock Howard Stern\\'s rise to fame and infamy.  I was thinking this film was gonna really suck going by a lot of the movie previews prior to its release, but I was sorely and happily mistaken.The film is perfectly structured, perfectly written, and it\\'s absolute travesty that Howard wasn\\'t nominated for an Oscar for best actor!  Here\\'s what the Oscar nominees shoulda been for this film: Howard Stern for Best Actor, Best Director, and Best Adapted Screenplay.Private Parts also manages to take a fresh approach on the old \"woman having a noisy orgasm\" comedy scene.  Yes, this flick is one of the few cases where the movie is actually better than the book.  Over, out, and all that jazz.', review_id='rw0429699', review_summary='Howard Stern IS The King Of All Media!', reviewer='newnoir', spoiler_tag=0),\n",
              " Row(helpful=['31', '37'], movie='Private Parts (1997)', rating='8', review_date='2 July 2001', review_detail='I am a big fan of Howard, and I\\'m sure fellow fans will also have a kick-a** time with this hilarious biopic of Stern\\'s road to stardom.  This is obviously not a professional biopic.  There\\'s even one scene, where Howard plays himself AS A TEEN!!  He tries to patch it up in the voice-over by saying, \"For this movie ya just have to believe.\"  There are many hilarious antics, and if you\\'re a fan of Stern I\\'m sure you will not stop laughing! If not, I can\\'t say you\\'ll have the time of your life.  I\\'ve heard many critics say that this movie is even suited for those who disapprove of Stern\\'s behavior.  I can\\'t say I agree, and for those who want to take the critics\\' word for it and give this movie a shot--enter at your own risk. Expect lots of Stern\\'s typically crude, offensive, tasteless humor.  Of course, you also get to see his sweeter side, and learn that his personality on radio does somewhat differ from that in real life.  Just like Andrew Dice Clay, his crude actions are exaggerated, and he really isn\\'t exactly like the pottymouthed jerk that the general public sees (or hears, in Howard\\'s case).  The open-minded moviegoer will probably come to that realization after viewing this movie, but others will be so turned off by Howard\\'s crude antics that they won\\'t feel compelled to sit through the entire running time--approximately two hours and fifteen minutes.  \"Private Parts\" is based on Howard\\'s autobiography, so this is pretty much the life of Howard through the eyes of...Howard.  Yet I can\\'t say this movie is a glorification of Stern--though he obviously boasts jokingly about his God-like status among his many followers (And I\\'m one of them--GO HOWARD!!!).  Personally, I still think there are a lot of closet Howard fans out there who are simply opposed (better yet, act like they\\'re opposed) to him because they would feel humiliated to say they\\'re not.  There are hypocrites out there, and I know some of them.  So for those of you who locked yourselves in that closet--get out and rent this movie!  Stop your whining!Many of Stern\\'s fellow cast members on the show appear as themselves--Fred Norris, Jackie Martling, Robin Quivers, Gary Del\\'Abate.  The other actors are good as well, especially Paul Giamatti who plays the NBC manager with a short, short fuse who springs from his seat if Howard were to utter the word \"penis.\"  Just his facial expressions alone crack me the hell up!  I\\'ve never seen Howard\\'s real wife Allison (I just found out she appears as an NBC operator, but I have to watch it again to spot her on screen), but Mary McCormack, who plays her, is absolutely BEE-U-TI-FUL!!  Nice casting, Betty Thomas.  She is stunning to look at, and the chemistry between she and Howard is electric.  I sometimes forget that she\\'s just PORTRAYING his wife. If you\\'re in the mood for Howard\\'s comical vulgarities, gratuitous nudity, cool 80s music and a damn entertaining comedy that will never tire out--\"Private Parts\" is DEFINITELY worth seeing!!  If you\\'re not a Stern fan, I\\'m pretty sure you\\'ll be croaking more than a sick frog, so don\\'t start preaching your blasphemous thoughts on Howard.  We really don\\'t have the time.  My score:  8 (out of 10)', review_id='rw0429698', review_summary='Awesome movie! One I never get tired of watching!', reviewer='mattymatt4ever', spoiler_tag=0),\n",
              " Row(helpful=['1', '3'], movie='Private Parts (1997)', rating=None, review_date='22 September 2001', review_detail=\"Well, I just watched that movie and I tell you: I had a GREAT time!! I had never heard of Howard Stern, especially here in Greece, but now I found out he's one cool dude! No matter what, check out this movie and you are going to have a great time...It really ROCKS!\", review_id='rw0429701', review_summary='Got to see that...', reviewer='ekokkinis', spoiler_tag=0),\n",
              " Row(helpful=['6', '8'], movie='Private Parts (1997)', rating='10', review_date='12 August 2001', review_detail='I detest Howard Stern and viewed this film under protest.  Surprisingly, I found it to be my favorite American film in some time.\\nWhilst the movie is based upon biographical material and many of the principal characters play themselves, director Betty Thomas does a marvelous job of creating a fresh feel of taking us behind the scenes.  Equally surprising is that Stern allows his warts and ego to be on full display. Private Parts, in its own way, is a far more trenchant essay on the state of the American entertainment industry than The Player or Network.', review_id='rw0429700', review_summary='Marvelous feature with shockingly original screenplay and approach', reviewer='simon_sparrow', spoiler_tag=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_rdd.toDF()"
      ],
      "metadata": {
        "id": "Ru3THo0sKbCK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tT3_3zDbc4M",
        "outputId": "e1b3043f-34f3-42cb-e975-272cd96aa27c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+--------------+-----------+\n",
            "| helpful|               movie|rating|      review_date|       review_detail|review_id|      review_summary|      reviewer|spoiler_tag|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+--------------+-----------+\n",
            "|  [1, 2]|Private Parts (1997)|     9|  3 November 1998|If you didn't kno...|rw0429696|Mr. Stern portray...|       tilly-3|          0|\n",
            "|[29, 41]|Private Parts (1997)|  null|     20 July 2001|This gem of a fli...|rw0429699|Howard Stern IS T...|       newnoir|          0|\n",
            "|[31, 37]|Private Parts (1997)|     8|      2 July 2001|I am a big fan of...|rw0429698|Awesome movie! On...|mattymatt4ever|          0|\n",
            "|  [1, 3]|Private Parts (1997)|  null|22 September 2001|Well, I just watc...|rw0429701|  Got to see that...|     ekokkinis|          0|\n",
            "|  [6, 8]|Private Parts (1997)|    10|   12 August 2001|I detest Howard S...|rw0429700|Marvelous feature...| simon_sparrow|          0|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistically summarizing about the data\n",
        "df.describe().show()"
      ],
      "metadata": {
        "id": "yoQ20sHUx406"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of rows and columns \n",
        "row = df.count()\n",
        "col = len(df.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "metadata": {
        "id": "oNkmCdNxeloe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2cdbd6-e957-4440-9207-9366f4eaa026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the Dataframe is: (50000, 9)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IOFmx-av1-xy",
        "outputId": "43c3f3ed-5b27-4ff1-84f0-993cd534b26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- movie: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- review_detail: string (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- review_summary: string (nullable = true)\n",
            " |-- reviewer: string (nullable = true)\n",
            " |-- spoiler_tag: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Printing Schema\n",
        "df.printSchema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dMpz8jVU1-xz",
        "outputId": "c35025fa-022e-4a69-c9ca-28da0a792cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['helpful',\n",
              " 'movie',\n",
              " 'rating',\n",
              " 'review_date',\n",
              " 'review_detail',\n",
              " 'review_id',\n",
              " 'review_summary',\n",
              " 'reviewer',\n",
              " 'spoiler_tag']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType, DateType, FloatType\n",
        "\n",
        "df2 = df \\\n",
        "  .withColumn(\"rating\" ,\n",
        "              df[\"rating\"]\n",
        "              .cast(FloatType()))   \\\n",
        "  .withColumn(\"spoiler_tag\"  ,\n",
        "              df[\"spoiler_tag\"]\n",
        "              .cast(FloatType()))"
      ],
      "metadata": {
        "id": "DTBKymoe6t0K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND5uCbPx7Qm1",
        "outputId": "ba5fc00f-ec06-4317-8170-dfb74745beb8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- movie: string (nullable = true)\n",
            " |-- rating: float (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- review_detail: string (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- review_summary: string (nullable = true)\n",
            " |-- reviewer: string (nullable = true)\n",
            " |-- spoiler_tag: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0J38M5L9mOS",
        "outputId": "65cc70ad-9dcf-4747-c4c2-617e79c87f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-----------------+---------------+--------------------+---------+-------------------+------------------+------------------+\n",
            "|summary|        movie|           rating|    review_date|       review_detail|review_id|     review_summary|          reviewer|       spoiler_tag|\n",
            "+-------+-------------+-----------------+---------------+--------------------+---------+-------------------+------------------+------------------+\n",
            "|  count|        50000|            45925|          50000|               50000|    50000|              50000|             50000|             50000|\n",
            "|   mean|         null|6.745998911268372|           null|                null|     null| 289.39285714285717| 791508.3571428572|           0.21898|\n",
            "| stddev|         null|2.969629967663795|           null|                null|     null|   717.327094646707|223427.99288760958|0.4135591616970949|\n",
            "|    min|#Alive (2020)|              1.0|1 February 2016|!! Contains a spo...|rw1985329|    !!Great Movie!!|  008_Bob-JamesBob|               0.0|\n",
            "|    max|  Ｉ島 (2019)|             10.0|9 February 2016|🤣....🍷That was ...|rw6059522|🦆ing Awesome film!|            zzmale|               1.0|\n",
            "+-------+-------------+-----------------+---------------+--------------------+---------+-------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE7cJzbw1-x0"
      },
      "source": [
        "### Drop Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n4wRgM4D1-x2",
        "outputId": "e75cc943-cd9c-404d-f696-934b3b4b3d83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+\n",
            "| helpful|               movie|rating|      review_date|       review_detail|review_id|      review_summary|       reviewer|spoiler_tag|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+\n",
            "|  [1, 2]|Private Parts (1997)|   9.0|  3 November 1998|If you didn't kno...|rw0429696|Mr. Stern portray...|        tilly-3|        0.0|\n",
            "|[29, 41]|Private Parts (1997)|  null|     20 July 2001|This gem of a fli...|rw0429699|Howard Stern IS T...|        newnoir|        0.0|\n",
            "|[31, 37]|Private Parts (1997)|   8.0|      2 July 2001|I am a big fan of...|rw0429698|Awesome movie! On...| mattymatt4ever|        0.0|\n",
            "|  [1, 3]|Private Parts (1997)|  null|22 September 2001|Well, I just watc...|rw0429701|  Got to see that...|      ekokkinis|        0.0|\n",
            "|  [6, 8]|Private Parts (1997)|  10.0|   12 August 2001|I detest Howard S...|rw0429700|Marvelous feature...|  simon_sparrow|        0.0|\n",
            "|  [6, 9]|Private Parts (1997)|  null|  24 October 2001|I used to watch S...|rw0429702|Funny. Typical Stern|         XRANDY|        0.0|\n",
            "|[37, 45]|Private Parts (1997)|  null|  11 January 2002|The true story of...|rw0429703|A little one-side...|    bob the moo|        0.0|\n",
            "|  [1, 2]|Private Parts (1997)|   8.0|  7 December 1998|Howard Stern mana...|rw0429707|Unexpected rudene...|       The Goth|        0.0|\n",
            "|  [2, 4]|Private Parts (1997)|   7.0|    15 April 2002|\"Private Parts\" m...|rw0429708|Shamelessly enter...|        shaun98|        0.0|\n",
            "|  [1, 2]|Private Parts (1997)|   7.0| 16 December 1998|Is the plaintive ...|rw0429711|\"I'm not bad, I'm...|        Rumples|        0.0|\n",
            "|  [1, 2]|Private Parts (1997)|   7.0|  8 December 1998|This film is very...|rw0429710|  Surprisingly Good!|         bek-12|        0.0|\n",
            "|  [4, 5]|Private Parts (1997)|   8.0| 28 December 1998|Having been a Ste...|rw0429712|The almost true s...|        ronpitt|        0.0|\n",
            "|  [0, 1]|Private Parts (1997)|   6.0| 30 December 1998|Any nut who skips...|rw0429713|Entertaining but ...|            emm|        0.0|\n",
            "|  [4, 6]|Private Parts (1997)|  null|      21 May 2002|I enjoyed Private...|rw0429715|  Somewhat appealing|     amlaped986|        0.0|\n",
            "|  [2, 4]|Private Parts (1997)|   9.0|     14 July 2002|I don't live in t...|rw0429717|This is a really ...|       Rock1984|        0.0|\n",
            "|[15, 19]|Private Parts (1997)|  10.0|  31 October 2002|Private Parts wen...|rw0429718|Part Comedy, Part...|walternefflives|        0.0|\n",
            "|  [0, 1]|Private Parts (1997)|  null|    16 March 2003|Man this movie is...|rw0429719|             AWESOME| lifehousefan13|        0.0|\n",
            "|  [1, 3]|Private Parts (1997)|  null|    17 April 2003|*SPOILER ALERT* *...|rw0429720|Howard Stern send...|       Dr. Gore|        1.0|\n",
            "|  [1, 3]|Private Parts (1997)|  null|    18 April 2003|PRIVATE PARTS (19...|rw0429721|The King Of All M...| george.schmidt|        0.0|\n",
            "|  [1, 6]|Private Parts (1997)|   3.0|      13 May 2003|By all means I'm ...|rw0429722|There is nothing ...| michaelRokeefe|        0.0|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.show() #Displaying samples "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_gby = df2.groupby(\"movie\").mean(\"rating\")"
      ],
      "metadata": {
        "id": "ROmD-_SlB1WZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gby.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAyX5wYBCZtk",
        "outputId": "d7e93fe2-f48b-4691-a260-a0f5e68b4c65"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|               movie|       avg(rating)|\n",
            "+--------------------+------------------+\n",
            "|Riot (1997 TV Movie)|               7.0|\n",
            "|I Love You Philli...|  6.03960396039604|\n",
            "|Super Paper Mario...|               7.0|\n",
            "|        Birth (2004)| 5.584905660377358|\n",
            "|       Quills (2000)| 7.066666666666666|\n",
            "|       Psycho (1960)|  8.95183486238532|\n",
            "|   The Graves (2009)|1.9285714285714286|\n",
            "|¿Qué apostamos? (...|              10.0|\n",
            "|Milf Training Cam...|              null|\n",
            "|      The Boy (2016)| 6.295833333333333|\n",
            "|Spring Shower (1932)|               5.0|\n",
            "|The Walking Dead:...|               6.0|\n",
            "| Day of Wrath (1943)| 7.454545454545454|\n",
            "|Arrow: Al Sah-Him...|               9.0|\n",
            "|CSI: Cyber (2015–...| 4.134831460674158|\n",
            "|The Curious Case ...| 7.397183098591549|\n",
            "|   Deadpool 2 (2018)| 6.588397790055248|\n",
            "|       Parada (2011)| 8.428571428571429|\n",
            "|Good Vibrations (...|            6.1875|\n",
            "|Abre los ojos (1997)|               8.2|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_gby.collect()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65lXaMudDUbP",
        "outputId": "bcaceb44-3727-4dfc-8101-47abb8c6897d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(movie='I Love You Phillip Morris (2009)', avg(rating)=6.03960396039604)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = df2.groupBy(\"movie\").sum(\"rating\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1OVX3Xu8ui-",
        "outputId": "fef56aca-49c3-4e81-c923-bd6b53094ce1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+-----------+\n",
            "|movie                                              |sum(rating)|\n",
            "+---------------------------------------------------+-----------+\n",
            "|Riot (1997 TV Movie)                               |28.0       |\n",
            "|I Love You Phillip Morris (2009)                   |610.0      |\n",
            "|Super Paper Mario (2007 Video Game)                |14.0       |\n",
            "|Birth (2004)                                       |296.0      |\n",
            "|Quills (2000)                                      |106.0      |\n",
            "|Psycho (1960)                                      |3903.0     |\n",
            "|The Graves (2009)                                  |27.0       |\n",
            "|¿Qué apostamos? (1993–2008)                        |10.0       |\n",
            "|Milf Training Camp 3 (2013 Video)                  |null       |\n",
            "|The Boy (2016)                                     |1511.0     |\n",
            "|Spring Shower (1932)                               |5.0        |\n",
            "|The Walking Dead: Scars (2019) Season 9, Episode 14|36.0       |\n",
            "|Day of Wrath (1943)                                |82.0       |\n",
            "|Arrow: Al Sah-Him (2015) Season 3, Episode 21      |36.0       |\n",
            "|CSI: Cyber (2015–2016)                             |368.0      |\n",
            "|The Curious Case of Benjamin Button (2008)         |2626.0     |\n",
            "|Deadpool 2 (2018)                                  |2385.0     |\n",
            "|Parada (2011)                                      |59.0       |\n",
            "|Good Vibrations (2012)                             |99.0       |\n",
            "|Abre los ojos (1997)                               |41.0       |\n",
            "+---------------------------------------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace null values in the ratings column with the computed mean\n",
        "df = df.na.fill(df_gby, subset=[\"ratings\"])"
      ],
      "metadata": {
        "id": "jvNGjueGD6RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Imputer method automatically replaces null values with mean values.\n",
        "imputer = Imputer(inputCols = [\"rating\"], outputCols = [\"rating-Out\"])\n",
        "\n",
        "#Fitting DataFrame into a model\n",
        "imputeModel = imputer.fit(df2) \n",
        "\n",
        "#Transforming the DataFrame\n",
        "df3=imputeModel.transform(df2) \n",
        "'''"
      ],
      "metadata": {
        "id": "PqVv8FFdzX7V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jAZOpOxR1-x5",
        "outputId": "8464aa46-b11e-4a46-bcf1-00485d7db47c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "| helpful|               movie|rating|      review_date|       review_detail|review_id|      review_summary|       reviewer|spoiler_tag|rating-Out|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "|  [1, 2]|Private Parts (1997)|   9.0|  3 November 1998|If you didn't kno...|rw0429696|Mr. Stern portray...|        tilly-3|        0.0|       9.0|\n",
            "|[29, 41]|Private Parts (1997)|  null|     20 July 2001|This gem of a fli...|rw0429699|Howard Stern IS T...|        newnoir|        0.0|  6.680677|\n",
            "|[31, 37]|Private Parts (1997)|   8.0|      2 July 2001|I am a big fan of...|rw0429698|Awesome movie! On...| mattymatt4ever|        0.0|       8.0|\n",
            "|  [1, 3]|Private Parts (1997)|  null|22 September 2001|Well, I just watc...|rw0429701|  Got to see that...|      ekokkinis|        0.0|  6.680677|\n",
            "|  [6, 8]|Private Parts (1997)|  10.0|   12 August 2001|I detest Howard S...|rw0429700|Marvelous feature...|  simon_sparrow|        0.0|      10.0|\n",
            "|  [6, 9]|Private Parts (1997)|  null|  24 October 2001|I used to watch S...|rw0429702|Funny. Typical Stern|         XRANDY|        0.0|  6.680677|\n",
            "|[37, 45]|Private Parts (1997)|  null|  11 January 2002|The true story of...|rw0429703|A little one-side...|    bob the moo|        0.0|  6.680677|\n",
            "|  [1, 2]|Private Parts (1997)|   8.0|  7 December 1998|Howard Stern mana...|rw0429707|Unexpected rudene...|       The Goth|        0.0|       8.0|\n",
            "|  [2, 4]|Private Parts (1997)|   7.0|    15 April 2002|\"Private Parts\" m...|rw0429708|Shamelessly enter...|        shaun98|        0.0|       7.0|\n",
            "|  [1, 2]|Private Parts (1997)|   7.0| 16 December 1998|Is the plaintive ...|rw0429711|\"I'm not bad, I'm...|        Rumples|        0.0|       7.0|\n",
            "|  [1, 2]|Private Parts (1997)|   7.0|  8 December 1998|This film is very...|rw0429710|  Surprisingly Good!|         bek-12|        0.0|       7.0|\n",
            "|  [4, 5]|Private Parts (1997)|   8.0| 28 December 1998|Having been a Ste...|rw0429712|The almost true s...|        ronpitt|        0.0|       8.0|\n",
            "|  [0, 1]|Private Parts (1997)|   6.0| 30 December 1998|Any nut who skips...|rw0429713|Entertaining but ...|            emm|        0.0|       6.0|\n",
            "|  [4, 6]|Private Parts (1997)|  null|      21 May 2002|I enjoyed Private...|rw0429715|  Somewhat appealing|     amlaped986|        0.0|  6.680677|\n",
            "|  [2, 4]|Private Parts (1997)|   9.0|     14 July 2002|I don't live in t...|rw0429717|This is a really ...|       Rock1984|        0.0|       9.0|\n",
            "|[15, 19]|Private Parts (1997)|  10.0|  31 October 2002|Private Parts wen...|rw0429718|Part Comedy, Part...|walternefflives|        0.0|      10.0|\n",
            "|  [0, 1]|Private Parts (1997)|  null|    16 March 2003|Man this movie is...|rw0429719|             AWESOME| lifehousefan13|        0.0|  6.680677|\n",
            "|  [1, 3]|Private Parts (1997)|  null|    17 April 2003|*SPOILER ALERT* *...|rw0429720|Howard Stern send...|       Dr. Gore|        1.0|  6.680677|\n",
            "|  [1, 3]|Private Parts (1997)|  null|    18 April 2003|PRIVATE PARTS (19...|rw0429721|The King Of All M...| george.schmidt|        0.0|  6.680677|\n",
            "|  [1, 6]|Private Parts (1997)|   3.0|      13 May 2003|By all means I'm ...|rw0429722|There is nothing ...| michaelRokeefe|        0.0|       3.0|\n",
            "+--------+--------------------+------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Describing the dataframe\n",
        "df3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ldVW-8Bh1-x5"
      },
      "outputs": [],
      "source": [
        "#Removing unnecessary columns\n",
        "df4 = df3.drop(df3['rating'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Describing the dataframe\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWkuJPlsqUfV",
        "outputId": "974d766d-b8f5-4cd8-b76f-e52e27b9d62d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "| helpful|               movie|      review_date|       review_detail|review_id|      review_summary|       reviewer|spoiler_tag|rating-Out|\n",
            "+--------+--------------------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "|  [1, 2]|Private Parts (1997)|  3 November 1998|If you didn't kno...|rw0429696|Mr. Stern portray...|        tilly-3|        0.0|       9.0|\n",
            "|[29, 41]|Private Parts (1997)|     20 July 2001|This gem of a fli...|rw0429699|Howard Stern IS T...|        newnoir|        0.0|  6.680677|\n",
            "|[31, 37]|Private Parts (1997)|      2 July 2001|I am a big fan of...|rw0429698|Awesome movie! On...| mattymatt4ever|        0.0|       8.0|\n",
            "|  [1, 3]|Private Parts (1997)|22 September 2001|Well, I just watc...|rw0429701|  Got to see that...|      ekokkinis|        0.0|  6.680677|\n",
            "|  [6, 8]|Private Parts (1997)|   12 August 2001|I detest Howard S...|rw0429700|Marvelous feature...|  simon_sparrow|        0.0|      10.0|\n",
            "|  [6, 9]|Private Parts (1997)|  24 October 2001|I used to watch S...|rw0429702|Funny. Typical Stern|         XRANDY|        0.0|  6.680677|\n",
            "|[37, 45]|Private Parts (1997)|  11 January 2002|The true story of...|rw0429703|A little one-side...|    bob the moo|        0.0|  6.680677|\n",
            "|  [1, 2]|Private Parts (1997)|  7 December 1998|Howard Stern mana...|rw0429707|Unexpected rudene...|       The Goth|        0.0|       8.0|\n",
            "|  [2, 4]|Private Parts (1997)|    15 April 2002|\"Private Parts\" m...|rw0429708|Shamelessly enter...|        shaun98|        0.0|       7.0|\n",
            "|  [1, 2]|Private Parts (1997)| 16 December 1998|Is the plaintive ...|rw0429711|\"I'm not bad, I'm...|        Rumples|        0.0|       7.0|\n",
            "|  [1, 2]|Private Parts (1997)|  8 December 1998|This film is very...|rw0429710|  Surprisingly Good!|         bek-12|        0.0|       7.0|\n",
            "|  [4, 5]|Private Parts (1997)| 28 December 1998|Having been a Ste...|rw0429712|The almost true s...|        ronpitt|        0.0|       8.0|\n",
            "|  [0, 1]|Private Parts (1997)| 30 December 1998|Any nut who skips...|rw0429713|Entertaining but ...|            emm|        0.0|       6.0|\n",
            "|  [4, 6]|Private Parts (1997)|      21 May 2002|I enjoyed Private...|rw0429715|  Somewhat appealing|     amlaped986|        0.0|  6.680677|\n",
            "|  [2, 4]|Private Parts (1997)|     14 July 2002|I don't live in t...|rw0429717|This is a really ...|       Rock1984|        0.0|       9.0|\n",
            "|[15, 19]|Private Parts (1997)|  31 October 2002|Private Parts wen...|rw0429718|Part Comedy, Part...|walternefflives|        0.0|      10.0|\n",
            "|  [0, 1]|Private Parts (1997)|    16 March 2003|Man this movie is...|rw0429719|             AWESOME| lifehousefan13|        0.0|  6.680677|\n",
            "|  [1, 3]|Private Parts (1997)|    17 April 2003|*SPOILER ALERT* *...|rw0429720|Howard Stern send...|       Dr. Gore|        1.0|  6.680677|\n",
            "|  [1, 3]|Private Parts (1997)|    18 April 2003|PRIVATE PARTS (19...|rw0429721|The King Of All M...| george.schmidt|        0.0|  6.680677|\n",
            "|  [1, 6]|Private Parts (1997)|      13 May 2003|By all means I'm ...|rw0429722|There is nothing ...| michaelRokeefe|        0.0|       3.0|\n",
            "+--------+--------------------+-----------------+--------------------+---------+--------------------+---------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of rows and columns \n",
        "row = df4.count()\n",
        "col = len(df4.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJs5vPZvR2H7",
        "outputId": "10d72407-4b26-4e69-c3b7-9ff80bd696ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the Dataframe is: (50000, 9)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "HWKxGQ7ZAcXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize DataFrame\n",
        "tokened = Tokenizer(inputCol=\"review_detail\", outputCol=\"words\")\n",
        "tokened_transformed = tokened.transform(df4)\n",
        "tokened_transformed.show()\n",
        "\n",
        "row = tokened_transformed.count()\n",
        "col = len(tokened_transformed.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB4Kah42R_No",
        "outputId": "4a301257-3dd9-47cb-d7ed-821a010d7584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+\n",
            "| helpful|               movie|review_date|       review_detail|review_id|      review_summary|            reviewer|spoiler_tag|rating-Out|               words|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+\n",
            "|  [1, 1]| After Life (2019– )| 3 May 2020|I enjoyed the fir...|rw5704482|Very Strong Season 2|       raeldor-96879|        0.0|       9.0|[i, enjoyed, the,...|\n",
            "|  [2, 2]|The Valhalla Murd...| 3 May 2020|I know Iceland is...|rw5704483|Icelandic detecti...|             dosleeb|        0.0|       6.0|[i, know, iceland...|\n",
            "|  [0, 0]|Special OPS (2020– )| 3 May 2020|Except K K , no o...|rw5704484|     Nothing special|     brightconscious|        0.0|       7.0|[except, k, k, ,,...|\n",
            "|  [5, 9]|   #BlackAF (2020– )| 3 May 2020|I'm guessing that...|rw5704485|            Good but|          gasconyway|        0.0|       8.0|[i'm, guessing, t...|\n",
            "|[26, 41]|  The Droving (2020)| 3 May 2020|Here's the truth....|rw5704487|    An honest review|        mmason-15867|        0.0|       2.0|[here's, the, tru...|\n",
            "|  [0, 1]|All About Eve (1950)| 3 May 2020|Having seen this ...|rw5704488|             Amazing|   schroederagustavo|        0.0|      10.0|[having, seen, th...|\n",
            "|  [0, 1]|Runaway Train (1985)| 3 May 2020|The movie had som...|rw5704489|Impressive action...|             welhof1|        0.0|       7.0|[the, movie, had,...|\n",
            "|  [7, 9]|Iron Fist (2017–2...| 3 May 2020|I loved it from t...|rw5704490|Another great Net...|             Evastar|        0.0|       9.0|[i, loved, it, fr...|\n",
            "|[16, 26]|The Half of It (I...| 3 May 2020|I see that Netfli...|rw5704491|Needed the other ...|              tioeta|        0.0|       4.0|[i, see, that, ne...|\n",
            "|  [1, 5]| This Is Us (2016– )| 3 May 2020|This is the show ...|rw5704492|All the Pearsons ...|       stephenrifkin|        0.0|       2.0|[this, is, the, s...|\n",
            "|  [2, 2]|  Closure (I) (2018)| 3 May 2020|This is a fun and...|rw5704494|  Fun and intriguing|    andrewtschroeder|        0.0|       9.0|[this, is, a, fun...|\n",
            "|  [3, 4]|  Unstoppable (2010)| 3 May 2020|A suspenseful thr...|rw5704493|Excellent last fi...|      UniqueParticle|        0.0|       8.0|[a, suspenseful, ...|\n",
            "|  [2, 3]|Dangerous Lies (2...| 3 May 2020|Highlight was Cam...|rw5704496|             Not bad|      Hellooo1234321|        0.0|  6.745999|[highlight, was, ...|\n",
            "| [8, 20]|Beastie Boys Stor...| 3 May 2020|A lot of excuses ...|rw5704497|    The apology tour|        flippereight|        0.0|       3.0|[a, lot, of, excu...|\n",
            "|  [0, 1]|Ruben Brandt, Col...| 3 May 2020|A fenomel animati...|rw5704500|Magnificent art-a...|         ovandoreyna|        0.0|      10.0|[a, fenomel, anim...|\n",
            "|  [1, 2]|Some Kind of Hate...| 3 May 2020|Some Kind Of Hate...|rw5704499|     Vengeful Spirit|              Pairic|        0.0|       7.0|[some, kind, of, ...|\n",
            "|  [0, 2]|    Cube Zero (2004)| 3 May 2020|I actually liked ...|rw5704501|       NOT FOR KIDS!|      driftingintime|        0.0|      10.0|[i, actually, lik...|\n",
            "|  [4, 4]|        Carne (1991)| 3 May 2020|Well, I just fini...|rw5704502|Like watching Noe...|Stay_away_from_th...|        0.0|       8.0|[well,, i, just, ...|\n",
            "|  [0, 1]|500 Days of Summe...| 3 May 2020|Ah Indies done by...|rw5704504|Cutie indie, just...|               vostf|        0.0|       5.0|[ah, indies, done...|\n",
            "|  [2, 3]|           8½ (1963)| 3 May 2020|Everybody should ...|rw5704503|Maybe the biggest...|          sharonrota|        0.0|      10.0|[everybody, shoul...|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 10)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"Wordsfiltered\")\n",
        "removed_frame = remover.transform(tokened_transformed)\n",
        "removed_frame.show()\n",
        "\n",
        "row = removed_frame.count()\n",
        "col = len(removed_frame.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZCstiFuSOr1",
        "outputId": "e0256e3b-7a73-418a-d10d-07f28fdb4f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
            "| helpful|               movie|review_date|       review_detail|review_id|      review_summary|            reviewer|spoiler_tag|rating-Out|               words|       Wordsfiltered|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
            "|  [1, 1]| After Life (2019– )| 3 May 2020|I enjoyed the fir...|rw5704482|Very Strong Season 2|       raeldor-96879|        0.0|       9.0|[i, enjoyed, the,...|[enjoyed, first, ...|\n",
            "|  [2, 2]|The Valhalla Murd...| 3 May 2020|I know Iceland is...|rw5704483|Icelandic detecti...|             dosleeb|        0.0|       6.0|[i, know, iceland...|[know, iceland, s...|\n",
            "|  [0, 0]|Special OPS (2020– )| 3 May 2020|Except K K , no o...|rw5704484|     Nothing special|     brightconscious|        0.0|       7.0|[except, k, k, ,,...|[except, k, k, ,,...|\n",
            "|  [5, 9]|   #BlackAF (2020– )| 3 May 2020|I'm guessing that...|rw5704485|            Good but|          gasconyway|        0.0|       8.0|[i'm, guessing, t...|[guessing, 62, ye...|\n",
            "|[26, 41]|  The Droving (2020)| 3 May 2020|Here's the truth....|rw5704487|    An honest review|        mmason-15867|        0.0|       2.0|[here's, the, tru...|[truth., much, mo...|\n",
            "|  [0, 1]|All About Eve (1950)| 3 May 2020|Having seen this ...|rw5704488|             Amazing|   schroederagustavo|        0.0|      10.0|[having, seen, th...|[seen, film, firs...|\n",
            "|  [0, 1]|Runaway Train (1985)| 3 May 2020|The movie had som...|rw5704489|Impressive action...|             welhof1|        0.0|       7.0|[the, movie, had,...|[movie, impressiv...|\n",
            "|  [7, 9]|Iron Fist (2017–2...| 3 May 2020|I loved it from t...|rw5704490|Another great Net...|             Evastar|        0.0|       9.0|[i, loved, it, fr...|[loved, first, ep...|\n",
            "|[16, 26]|The Half of It (I...| 3 May 2020|I see that Netfli...|rw5704491|Needed the other ...|              tioeta|        0.0|       4.0|[i, see, that, ne...|[see, netflix, te...|\n",
            "|  [1, 5]| This Is Us (2016– )| 3 May 2020|This is the show ...|rw5704492|All the Pearsons ...|       stephenrifkin|        0.0|       2.0|[this, is, the, s...|[show, people, no...|\n",
            "|  [2, 2]|  Closure (I) (2018)| 3 May 2020|This is a fun and...|rw5704494|  Fun and intriguing|    andrewtschroeder|        0.0|       9.0|[this, is, a, fun...|[fun, intriguing,...|\n",
            "|  [3, 4]|  Unstoppable (2010)| 3 May 2020|A suspenseful thr...|rw5704493|Excellent last fi...|      UniqueParticle|        0.0|       8.0|[a, suspenseful, ...|[suspenseful, thr...|\n",
            "|  [2, 3]|Dangerous Lies (2...| 3 May 2020|Highlight was Cam...|rw5704496|             Not bad|      Hellooo1234321|        0.0|  6.745999|[highlight, was, ...|[highlight, camil...|\n",
            "| [8, 20]|Beastie Boys Stor...| 3 May 2020|A lot of excuses ...|rw5704497|    The apology tour|        flippereight|        0.0|       3.0|[a, lot, of, excu...|[lot, excuses, ap...|\n",
            "|  [0, 1]|Ruben Brandt, Col...| 3 May 2020|A fenomel animati...|rw5704500|Magnificent art-a...|         ovandoreyna|        0.0|      10.0|[a, fenomel, anim...|[fenomel, animati...|\n",
            "|  [1, 2]|Some Kind of Hate...| 3 May 2020|Some Kind Of Hate...|rw5704499|     Vengeful Spirit|              Pairic|        0.0|       7.0|[some, kind, of, ...|[kind, hate:, lin...|\n",
            "|  [0, 2]|    Cube Zero (2004)| 3 May 2020|I actually liked ...|rw5704501|       NOT FOR KIDS!|      driftingintime|        0.0|      10.0|[i, actually, lik...|[actually, liked,...|\n",
            "|  [4, 4]|        Carne (1991)| 3 May 2020|Well, I just fini...|rw5704502|Like watching Noe...|Stay_away_from_th...|        0.0|       8.0|[well,, i, just, ...|[well,, finished,...|\n",
            "|  [0, 1]|500 Days of Summe...| 3 May 2020|Ah Indies done by...|rw5704504|Cutie indie, just...|               vostf|        0.0|       5.0|[ah, indies, done...|[ah, indies, done...|\n",
            "|  [2, 3]|           8½ (1963)| 3 May 2020|Everybody should ...|rw5704503|Maybe the biggest...|          sharonrota|        0.0|      10.0|[everybody, shoul...|[everybody, watch...|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 11)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"Wordsfiltered\", outputCol=\"hashedValues\")\n",
        "\n",
        "# Transform into a DF\n",
        "hashed_df = hashing.transform(removed_frame)\n",
        "hashed_df.show()\n",
        "\n",
        "row = hashed_df.count()\n",
        "col = len(hashed_df.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMSTO6OTSWs7",
        "outputId": "5dd66387-ae1f-432f-8884-22b02462c03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+--------------------+\n",
            "| helpful|               movie|review_date|       review_detail|review_id|      review_summary|            reviewer|spoiler_tag|rating-Out|               words|       Wordsfiltered|        hashedValues|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+--------------------+\n",
            "|  [1, 1]| After Life (2019– )| 3 May 2020|I enjoyed the fir...|rw5704482|Very Strong Season 2|       raeldor-96879|        0.0|       9.0|[i, enjoyed, the,...|[enjoyed, first, ...|(262144,[2437,125...|\n",
            "|  [2, 2]|The Valhalla Murd...| 3 May 2020|I know Iceland is...|rw5704483|Icelandic detecti...|             dosleeb|        0.0|       6.0|[i, know, iceland...|[know, iceland, s...|(262144,[16794,21...|\n",
            "|  [0, 0]|Special OPS (2020– )| 3 May 2020|Except K K , no o...|rw5704484|     Nothing special|     brightconscious|        0.0|       7.0|[except, k, k, ,,...|[except, k, k, ,,...|(262144,[29550,68...|\n",
            "|  [5, 9]|   #BlackAF (2020– )| 3 May 2020|I'm guessing that...|rw5704485|            Good but|          gasconyway|        0.0|       8.0|[i'm, guessing, t...|[guessing, 62, ye...|(262144,[5675,853...|\n",
            "|[26, 41]|  The Droving (2020)| 3 May 2020|Here's the truth....|rw5704487|    An honest review|        mmason-15867|        0.0|       2.0|[here's, the, tru...|[truth., much, mo...|(262144,[991,1889...|\n",
            "|  [0, 1]|All About Eve (1950)| 3 May 2020|Having seen this ...|rw5704488|             Amazing|   schroederagustavo|        0.0|      10.0|[having, seen, th...|[seen, film, firs...|(262144,[645,3889...|\n",
            "|  [0, 1]|Runaway Train (1985)| 3 May 2020|The movie had som...|rw5704489|Impressive action...|             welhof1|        0.0|       7.0|[the, movie, had,...|[movie, impressiv...|(262144,[5561,833...|\n",
            "|  [7, 9]|Iron Fist (2017–2...| 3 May 2020|I loved it from t...|rw5704490|Another great Net...|             Evastar|        0.0|       9.0|[i, loved, it, fr...|[loved, first, ep...|(262144,[56844,62...|\n",
            "|[16, 26]|The Half of It (I...| 3 May 2020|I see that Netfli...|rw5704491|Needed the other ...|              tioeta|        0.0|       4.0|[i, see, that, ne...|[see, netflix, te...|(262144,[1904,243...|\n",
            "|  [1, 5]| This Is Us (2016– )| 3 May 2020|This is the show ...|rw5704492|All the Pearsons ...|       stephenrifkin|        0.0|       2.0|[this, is, the, s...|[show, people, no...|(262144,[13644,29...|\n",
            "|  [2, 2]|  Closure (I) (2018)| 3 May 2020|This is a fun and...|rw5704494|  Fun and intriguing|    andrewtschroeder|        0.0|       9.0|[this, is, a, fun...|[fun, intriguing,...|(262144,[5370,952...|\n",
            "|  [3, 4]|  Unstoppable (2010)| 3 May 2020|A suspenseful thr...|rw5704493|Excellent last fi...|      UniqueParticle|        0.0|       8.0|[a, suspenseful, ...|[suspenseful, thr...|(262144,[4235,125...|\n",
            "|  [2, 3]|Dangerous Lies (2...| 3 May 2020|Highlight was Cam...|rw5704496|             Not bad|      Hellooo1234321|        0.0|  6.745999|[highlight, was, ...|[highlight, camil...|(262144,[2257,934...|\n",
            "| [8, 20]|Beastie Boys Stor...| 3 May 2020|A lot of excuses ...|rw5704497|    The apology tour|        flippereight|        0.0|       3.0|[a, lot, of, excu...|[lot, excuses, ap...|(262144,[19352,20...|\n",
            "|  [0, 1]|Ruben Brandt, Col...| 3 May 2020|A fenomel animati...|rw5704500|Magnificent art-a...|         ovandoreyna|        0.0|      10.0|[a, fenomel, anim...|[fenomel, animati...|(262144,[47435,50...|\n",
            "|  [1, 2]|Some Kind of Hate...| 3 May 2020|Some Kind Of Hate...|rw5704499|     Vengeful Spirit|              Pairic|        0.0|       7.0|[some, kind, of, ...|[kind, hate:, lin...|(262144,[956,4757...|\n",
            "|  [0, 2]|    Cube Zero (2004)| 3 May 2020|I actually liked ...|rw5704501|       NOT FOR KIDS!|      driftingintime|        0.0|      10.0|[i, actually, lik...|[actually, liked,...|(262144,[3158,270...|\n",
            "|  [4, 4]|        Carne (1991)| 3 May 2020|Well, I just fini...|rw5704502|Like watching Noe...|Stay_away_from_th...|        0.0|       8.0|[well,, i, just, ...|[well,, finished,...|(262144,[2432,927...|\n",
            "|  [0, 1]|500 Days of Summe...| 3 May 2020|Ah Indies done by...|rw5704504|Cutie indie, just...|               vostf|        0.0|       5.0|[ah, indies, done...|[ah, indies, done...|(262144,[6561,978...|\n",
            "|  [2, 3]|           8½ (1963)| 3 May 2020|Everybody should ...|rw5704503|Maybe the biggest...|          sharonrota|        0.0|      10.0|[everybody, shoul...|[everybody, watch...|(262144,[6512,100...|\n",
            "+--------+--------------------+-----------+--------------------+---------+--------------------+--------------------+-----------+----------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 12)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-YlyaKGSkA7",
        "outputId": "9fd0b2c0-4877-46b1-9cb4-5d077dd0fd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(helpful=['1', '1'], movie='After Life (2019– )', rating='9', review_date='3 May 2020', review_detail=\"I enjoyed the first season, but I must say I think season 2 is even stronger. Ricky does a great job as both writer, actor and director and brings out the best in a superb supporting cast. If there was one thing I'd change, I'd like to hear him talk about himself less with other people and speak more in the third person, but other than that it's pretty hard to fault this funny yet emotional comedy.\", review_id='rw5704482', review_summary='Very Strong Season 2', reviewer='raeldor-96879', spoiler_tag=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7qO_DdwUKtL",
        "outputId": "ace46f33-0265-492d-b66b-5f5049c80efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(helpful=['1', '1'], movie='After Life (2019– )', review_date='3 May 2020', review_detail=\"I enjoyed the first season, but I must say I think season 2 is even stronger. Ricky does a great job as both writer, actor and director and brings out the best in a superb supporting cast. If there was one thing I'd change, I'd like to hear him talk about himself less with other people and speak more in the third person, but other than that it's pretty hard to fault this funny yet emotional comedy.\", review_id='rw5704482', review_summary='Very Strong Season 2', reviewer='raeldor-96879', spoiler_tag=0.0, rating-Out=9.0, words=['i', 'enjoyed', 'the', 'first', 'season,', 'but', 'i', 'must', 'say', 'i', 'think', 'season', '2', 'is', 'even', 'stronger.', 'ricky', 'does', 'a', 'great', 'job', 'as', 'both', 'writer,', 'actor', 'and', 'director', 'and', 'brings', 'out', 'the', 'best', 'in', 'a', 'superb', 'supporting', 'cast.', 'if', 'there', 'was', 'one', 'thing', \"i'd\", 'change,', \"i'd\", 'like', 'to', 'hear', 'him', 'talk', 'about', 'himself', 'less', 'with', 'other', 'people', 'and', 'speak', 'more', 'in', 'the', 'third', 'person,', 'but', 'other', 'than', 'that', \"it's\", 'pretty', 'hard', 'to', 'fault', 'this', 'funny', 'yet', 'emotional', 'comedy.'], Wordsfiltered=['enjoyed', 'first', 'season,', 'must', 'say', 'think', 'season', '2', 'even', 'stronger.', 'ricky', 'great', 'job', 'writer,', 'actor', 'director', 'brings', 'best', 'superb', 'supporting', 'cast.', 'one', 'thing', 'change,', 'like', 'hear', 'talk', 'less', 'people', 'speak', 'third', 'person,', 'pretty', 'hard', 'fault', 'funny', 'yet', 'emotional', 'comedy.'], hashedValues=SparseVector(262144, {2437: 1.0, 12524: 1.0, 13981: 1.0, 21823: 1.0, 23071: 1.0, 55270: 1.0, 70065: 1.0, 72125: 1.0, 85771: 1.0, 86447: 1.0, 99197: 1.0, 105627: 1.0, 111370: 1.0, 114003: 1.0, 114922: 1.0, 121555: 1.0, 123327: 1.0, 147164: 1.0, 153423: 1.0, 155732: 1.0, 158421: 1.0, 162479: 1.0, 166027: 1.0, 168211: 1.0, 171222: 1.0, 172284: 1.0, 174966: 1.0, 181664: 1.0, 185559: 1.0, 188835: 1.0, 194194: 1.0, 207308: 1.0, 208258: 1.0, 223262: 1.0, 229407: 1.0, 240840: 1.0, 249163: 1.0, 256493: 1.0, 261870: 1.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Nc1NGsJHgvoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df4['review_detail', 'spoiler_tag']"
      ],
      "metadata": {
        "id": "dkmad_F4WJr-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-T-_0WAWkX4",
        "outputId": "94678dca-5367-4087-fa3f-0db86e777379"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+\n",
            "|       review_detail|spoiler_tag|\n",
            "+--------------------+-----------+\n",
            "|If you didn't kno...|        0.0|\n",
            "|This gem of a fli...|        0.0|\n",
            "|I am a big fan of...|        0.0|\n",
            "|Well, I just watc...|        0.0|\n",
            "|I detest Howard S...|        0.0|\n",
            "+--------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "training, testing = df_1.randomSplit([0.7, 0.3],1)"
      ],
      "metadata": {
        "id": "8yuEc2OaWDjr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Dataset Count: \" + str(df_1.count()))\n",
        "print(\"Training Dataset Count: \" + str(training.count()))\n",
        "print(\"Test Dataset Count: \" + str(testing.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD_Z_O-KXnY3",
        "outputId": "801cb14d-01f9-476d-ae4e-a8ff15ad7f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 50000\n",
            "Training Dataset Count: 34993\n",
            "Test Dataset Count: 15007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show training data \n",
        "training.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fRKoQuSXzYB",
        "outputId": "c89fed29-a144-4f31-c0ac-712a90952fc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+\n",
            "|       review_detail|spoiler_tag|\n",
            "+--------------------+-----------+\n",
            "|! am reminded of ...|        0.0|\n",
            "|!!!! SPOILERS !!!...|        1.0|\n",
            "|!!!SPOILERS!!!Alt...|        1.0|\n",
            "|!Warning: This re...|        1.0|\n",
            "|\" . . . can keep ...|        1.0|\n",
            "|\" . . . don't the...|        1.0|\n",
            "|\" . . . it's not ...|        1.0|\n",
            "|\" . . . of the Wo...|        1.0|\n",
            "|\" . . . we humans...|        1.0|\n",
            "|\" The scariest Am...|        0.0|\n",
            "|\" Warning Spoiler...|        1.0|\n",
            "|\"21 Jump Street\" ...|        0.0|\n",
            "|\"227\" is a comedy...|        0.0|\n",
            "|\"50-50 kaus Dur j...|        0.0|\n",
            "|\"8 thousands year...|        1.0|\n",
            "|\"88 Minutes\" is a...|        0.0|\n",
            "|\"9\" is an animate...|        0.0|\n",
            "|\"A Chump at Oxfor...|        1.0|\n",
            "|\"A Friend of the ...|        0.0|\n",
            "|\"A Gander at Moth...|        1.0|\n",
            "+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the data types\n",
        "training.dtypes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8m3hghAX4ho",
        "outputId": "7a9efd48-6722-42fb-c6a4-885ef2ab6546"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('review_detail', 'string'), ('spoiler_tag', 'float')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION MODEL \n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='spoiler_tag',outputCol='label')\n",
        "# code to change positive sentiment to 1 values - stringOrderType=\"frequencyAsc\"\n",
        "tokenizer = Tokenizer(inputCol=\"review_detail\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.001)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lr])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "lrmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_lr = lrmodel.transform(testing)\n",
        "\n",
        "predictions_lr.filter(predictions_lr['label'] == 0) \\\n",
        "    .select(\"review_detail\",\"Wordsfiltered\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"Logistic Regression F1 Score: \", f1_eval.evaluate(predictions_lr))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Logistic Regression Accuracy: \", accuracy_score.evaluate(predictions_lr))"
      ],
      "metadata": {
        "id": "dx90K51LZGrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2b21a0-9d34-4b30-bd8a-78766a905c86"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----------+-----+----------+\n",
            "|                 review_detail|                 Wordsfiltered|                      features|probability|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----------+-----+----------+\n",
            "|A bankrupted aristocrat cal...|[a, bankrupted, aristocrat,...|(262144,[3785,4714,5381,548...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|Arranca en un Londres que b...|[arranca, en, un, londres, ...|(262144,[183,1350,1493,1823...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|Season Five opens with this...|[season, five, opens, with,...|(262144,[2061,2977,3276,409...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|Jagga Jasoos (2017): When a...|[jagga, jasoos, (2017):, wh...|(262144,[2437,3023,3388,392...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|Aside from space, there can...|[aside, from, space,, there...|(262144,[619,672,896,1277,2...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|Si puedes conformarte con a...|[si, puedes, conformarte, c...|(262144,[764,1781,3165,3755...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|La cinta es muy cambiante e...|[la, cinta, es, muy, cambia...|(262144,[138,1815,3165,6512...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|It is an agreeable picture ...|[it, is, an, agreeable, pic...|(262144,[521,1046,1303,1331...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|\"Llevar a alguien al huerto...|[\"llevar, a, alguien, al, h...|(262144,[1513,1585,2895,316...|  [1.0,0.0]|  0.0|       0.0|\n",
            "|`Apt Pupil', based on the S...|[`apt, pupil',, based, on, ...|(262144,[303,991,1225,2325,...|  [1.0,0.0]|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Logistic Regression F1 Score:  0.7818478201505026\n",
            "Logistic Regression Accuracy:  0.7919932571067556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### NAIVE BAYES MODEL\n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='spoiler_tag',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"review_detail\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "nb = NaiveBayes(smoothing=1)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, nb])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "nbmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_nb = nbmodel.transform(testing)\n",
        "\n",
        "predictions_nb.filter(predictions_nb['label'] == 0) \\\n",
        "    .select(\"review_detail\",\"Wordsfiltered\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"Naive Bayes F1 Score: \", f1_eval.evaluate(predictions_nb))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Naive Bayes Accuracy: \", accuracy_score.evaluate(predictions_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIauDq_Eb3JD",
        "outputId": "046ab8f9-d121-465d-df87-5513cc06e60b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "|                 review_detail|                 Wordsfiltered|                      features|                 probability|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "|'Tiny Toon Adventures' prov...|['tiny, toon, adventures', ...|(262144,[27,646,1891,2488,2...|[1.0,1.1074082600811119E-16]|  0.0|       0.0|\n",
            "|Fleischer's Popeye cartoons...|[fleischer's, popeye, carto...|(262144,[3121,3133,6660,702...|[1.0,1.0875790387473111E-16]|  0.0|       0.0|\n",
            "|''Godhi Banna Sadharna Maik...|[''godhi, banna, sadharna, ...|(262144,[337,1300,1595,3680...|[1.0,1.0868189327780771E-16]|  0.0|       0.0|\n",
            "|___________________________...|[__________________________...|(262144,[521,2050,2392,2437...|[1.0,1.0845654388358371E-16]|  0.0|       0.0|\n",
            "|Inglorious Bastards is one ...|[inglorious, bastards, is, ...|(262144,[429,780,1889,2491,...|[1.0,1.0733415134443655E-16]|  0.0|       0.0|\n",
            "|Loved 'Foyle's War' and was...|[loved, 'foyle's, war', and...|(262144,[2306,3535,4210,421...|[1.0,1.0649088369716181E-16]|  0.0|       0.0|\n",
            "|#FinalVerdictLootcase is a ...|[#finalverdictlootcase, is,...|(262144,[1020,2731,4714,553...|[1.0,1.0641121798720616E-16]|  0.0|       0.0|\n",
            "|I have a long and detailed ...|[i, have, a, long, and, det...|(262144,[991,1578,1696,1778...|[1.0,1.0625422559627859E-16]|  0.0|       0.0|\n",
            "|The cast actually made me w...|[the, cast, actually, made,...|(262144,[3333,7644,9589,211...|[1.0,1.0320565720171302E-16]|  0.0|       0.0|\n",
            "|'The Aspern Papers' is a gr...|['the, aspern, papers', is,...|(262144,[1189,2306,6512,686...|[1.0,1.0171771752402638E-16]|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Naive Bayes F1 Score:  0.7840851494732808\n",
            "Naive Bayes Accuracy:  0.7821342851322747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bslTNuNxeLxd",
        "outputId": "a3e8a551-d8ef-4b71-eea3-047bdb774724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                 review_detail|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\"#Captured\" is an amateuris...|[\"#captured\", is, an, amate...|(262144,[1696,2160,4777,538...|  0.0|       0.0|\n",
            "|\"'Odd' Thomas,\" is the anti...|[\"'odd', thomas,\", is, the,...|(262144,[6346,8538,10049,11...|  0.0|       1.0|\n",
            "|\"'tis a very silly show\"Thi...|[\"'tis, a, very, silly, sho...|(262144,[3924,3928,5381,563...|  0.0|       0.0|\n",
            "|\"...The film is like a batt...|[\"...the, film, is, like, a...|(262144,[2437,3023,3329,347...|  0.0|       0.0|\n",
            "|\"21 Jump Street\" is a comed...|[\"21, jump, street\", is, a,...|(262144,[1968,3613,4106,421...|  0.0|       0.0|\n",
            "|\"A Little Trip To Heaven\" i...|[\"a, little, trip, to, heav...|(262144,[5507,6346,7400,787...|  0.0|       0.0|\n",
            "|\"A Simple Plan\" has to go d...|[\"a, simple, plan\", has, to...|(262144,[107,3165,10049,104...|  0.0|       0.0|\n",
            "|\"A Simple Plan\" is a movie ...|[\"a, simple, plan\", is, a, ...|(262144,[6034,6346,10049,10...|  0.0|       0.0|\n",
            "|\"A classic 80's style movie...|[\"a, classic, 80's, style, ...|(262144,[1004,2548,4714,490...|  0.0|       0.0|\n",
            "|\"A little bit of kindness g...|[\"a, little, bit, of, kindn...|(262144,[2306,2931,7994,880...|  0.0|       1.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "SVM F1 Score:  0.7851842590516469\n",
            "SVM Accuracy:  0.8011909295686497\n"
          ]
        }
      ],
      "source": [
        "### SVM MODEL \n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='spoiler_tag',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"review_detail\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "lsvc = LinearSVC()\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lsvc])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "lsvcmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_svm = lsvcmodel.transform(testing)\n",
        "\n",
        "predictions_svm.filter(predictions_svm['label'] == 0) \\\n",
        "    .select(\"review_detail\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"SVM F1 Score: \", f1_eval.evaluate(predictions_svm))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"SVM Accuracy: \", accuracy_score.evaluate(predictions_svm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation for SVM model\n",
        "from pyspark.ml.feature import HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lsvc])\n",
        "\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    estimatorParamMaps=ParamGridBuilder().build(),\n",
        "                    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                    numFolds=5)\n",
        "model_svc = cv.fit(training)\n",
        "# Tranform the model with the testing data\n",
        "predictions = model_svc.transform(testing)\n",
        "predictions.filter(predictions['label'] == 0) \\\n",
        "    .select(\"review_detail\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ],
      "metadata": {
        "id": "iolrzQDf-FNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing metrics\n",
        "avgMetricsGrid_svc = model_svc.avgMetrics\n",
        "print (avgMetricsGrid_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGU5qrs_cOrP",
        "outputId": "eecc6206-5eb4-47df-c08e-f86144f9cb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7361204746769922]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation for SVM model\n",
        "from pyspark.ml.feature import HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, nb])\n",
        "\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    estimatorParamMaps=ParamGridBuilder().build(),\n",
        "                    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                    numFolds=5)\n",
        "model_nb = cv.fit(training)\n",
        "# Tranform the model with the testing data\n",
        "predictions = model_nb.transform(testing)\n",
        "predictions.filter(predictions['label'] == 0) \\\n",
        "    .select(\"review_detail\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1op4tbMPvPKR",
        "outputId": "84fa6406-892b-44bb-bb99-31a5a7856cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                 review_detail|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\" Good Casting \" had indeed...|[\", good, casting, \", had, ...|(262144,[6512,7014,7400,978...|  0.0|       0.0|\n",
            "|\" My uncles who were full u...|[\", my, uncles, who, were, ...|(262144,[1968,3837,4493,112...|  0.0|       0.0|\n",
            "|\" Noble, my love \" was simp...|[\", noble,, my, love, \", wa...|(262144,[2325,2977,3924,392...|  0.0|       1.0|\n",
            "|\" Now you see me \" is a mov...|[\", now, you, see, me, \", i...|(262144,[5454,6512,8538,172...|  0.0|       0.0|\n",
            "|\" Pegasus Market \" was a ro...|[\", pegasus, market, \", was...|(262144,[2977,6512,8145,142...|  0.0|       0.0|\n",
            "|\"10 seconds\" is a British s...|[\"10, seconds\", is, a, brit...|(262144,[4723,8287,12035,17...|  0.0|       0.0|\n",
            "|\"99.9 La frecuencia del ter...|[\"99.9, la, frecuencia, del...|(262144,[1815,5054,6151,797...|  0.0|       0.0|\n",
            "|\"A Minute to Pray, A Second...|[\"a, minute, to, pray,, a, ...|(262144,[2701,6699,7136,936...|  0.0|       0.0|\n",
            "|\"A new time, a new odyssey,...|[\"a, new, time,, a, new, od...|(262144,[2977,3924,7296,853...|  0.0|       1.0|\n",
            "|\"Afterimage\" was a hit at t...|[\"afterimage\", was, a, hit,...|(262144,[5550,7796,16657,17...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing metrics\n",
        "avgMetricsGrid_nb = model_nb.avgMetrics\n",
        "print (avgMetricsGrid_nb)"
      ],
      "metadata": {
        "id": "xily-pIf-IIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Files"
      ],
      "metadata": {
        "id": "foIcxbx3twLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = ['/content/drive/MyDrive/BigData_FinalProject/Data/part-01.json',\n",
        "             '/content/drive/MyDrive/BigData_FinalProject/Data/part-02.json',\n",
        "             '/content/drive/MyDrive/BigData_FinalProject/Data/part-03.json',\n",
        "             '/content/drive/MyDrive/BigData_FinalProject/Data/part-04.json',\n",
        "             '/content/drive/MyDrive/BigData_FinalProject/Data/part-05.json',\n",
        "             '/content/drive/MyDrive/BigData_FinalProject/Data/part-06.json']"
      ],
      "metadata": {
        "id": "ldNRHe0iR5Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "k = 0\n",
        "for file_ in file_list:\n",
        "  # Open the file to be splitted\n",
        "  with open((file_), 'r') as f1:\n",
        "    ll = json.load(f1)\n",
        "    #total length size of the json file\n",
        "    print(len(ll))\n",
        "    #in here 50000 means we getting splits of 50000 reviews\n",
        "    size_of_the_split=50000\n",
        "    total = len(ll) // size_of_the_split\n",
        "    # Number of splits\n",
        "    print(total+1)\n",
        "    for i in range(total+1):\n",
        "      k = k + 1\n",
        "      json.dump(ll[i * size_of_the_split:(i + 1) * size_of_the_split], \n",
        "                open(\"/content/drive/MyDrive/BigData_FinalProject/Splits/part\"+ str(k)+\".json\", 'w'))\n",
        "      print(k)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwzKe3xJSuv9",
        "outputId": "75649ae0-f0ed-4d3d-f643-f270cb293699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1010293\n",
            "21\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "1012212\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "1015000\n",
            "21\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "1019000\n",
            "21\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "1014997\n",
            "21\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "499997\n",
            "10\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n"
          ]
        }
      ]
    }
  ]
}